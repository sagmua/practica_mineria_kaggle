---
title: "Competicion Kaggle Knn"
author: "Carmen Biedma Rodriguez"
date: "4 de febrero de 2019"
output: pdf_document
---

```{r}
library(dplyr)
library(Hmisc)
library(caret)
library(mice)
library(VIM)
library(class)
library(outliers)
library(ggplot2)
library(mvoutlier)
library(FSelector)
library(corrplot)

source("../funcionesAux.R")
```

```{r}
datos <- read.csv("../train.csv",na.strings=c(" ","NA","?"))
test <- read.csv("../test.csv",na.strings=c(" ","NA","?"))
```

#Visi?n preliminar de los datos

```{r}
nrow(datos)
ncol(datos)
```

```{r}
summary(datos)
```

Como podemos ver, es un problema que tiene 50 variables descriptivas y una de clasificaci?n. Una de las cosas m?s importantes que nos proporciona este resumen de los datos es que todas las varables tienen valores perdidos, por lo que ser? un problema a solucionar. Por otro lado, podemos ver que los dominios de las variables son muy diferentes unos de otros por lo que tambi?n convendr? aplicar un centrado y escalado. ?sto ?ltimo es muy importante ya que vamos a aplicar un m?todo basado en distancias.

Otra de las cosas que ser?a interesante observar es si tenemos un problema desbalanceado, para ello crearemos una tabla en la que veremos las instancias que hay de una clase y de otra.

```{r}
table(datos$C)
```

Como podemos ver, es un problema desbalanceado, por lo que ser? un aspecto a tratar en el preprocesamiento de los datos.


#ESCALADO Y CENTRADO DE LOS DATOS

```{r}
datosPrep <- caret::preProcess(datos[,-ncol(datos)],method = c("center","scale"))
datos[,-ncol(datos)] <- predict(datosPrep,datos[,-ncol(datos)])
datosPrep <- caret::preProcess(test,method = c("center","scale"))
test <- predict(datosPrep,test)
```



#Imputación de valores perdidos.

En primer lugar, vamos a eliminar las instancias qeu tienen un porcentaje de valores peridos superior aun umbral previamente establecido.

En primer lugar, con el siguiente comando, calcularemos el porcentaje de valores perdidos que tiene cada fila. 


```{r}
porcentajes <- apply(datos,1, function(x) sum(is.na(x))) / ncol(datos) * 100
eliminar <- porcentajes>5
which(eliminar == TRUE)
```

Como vemos, no hay ninguna instancia que podamos eliminar siguiendo este criterio, por lo que tendremos que realizar otra tarea para eliminar los valores perdidos.

A continuaci?n se imputar?n los valores perdidos. Esto quiere decir que a cada uno de ellos se le asignar? unn valor. Dicho valor puede ser el mismo para todos, la media o cualquier otra medida basada en los dem?s datos de la variable o un valor proporcionado por cualquier m?todo de imputaci?n.

Vamos a ver el patr?n de datos perdidos que sigue nuestro conjunto de datos usando la libreria mice. Como podemos ver a continuaci?n, tenemos un total de 7778 variables que no tienen ningun valor perdido.

```{r}
patron <- mice::md.pattern(datos)
print(patron)
```

Si observamos gr?ficamente el resultado proporcionado por el patr?n, vemos que no hay ninguna variable que tenga m?s de un valor perdido. Esto explica que en el paso anterior no se haya eliminado ninguna instancia, ya que, que una de las variables est? perdida no es raz?n suficiente como para poder eliminar la fila conmpleta.

Hay otra libreria que nos permite visualizar de distintas formas los valores perdidos de un conjunto de datos. Veamos a continuaci?n las utilidades que nos proporciona.

```{r}
plot <- VIM::aggr(datos,col=c('blue','red'),numbers=TRUE,sortVars=TRUE,labels=names(data),
                  cex.axis=.5,gap=1,ylab=c("Gr?fico de datos perdidos","Patron"))
```

A continuaci?n se procede a realizar la imputaci?n:________________________--

```{r}
completos <- mice::ncc(datos)
incompletos <- mice::nic(datos)
cat("COMPLETOS = ", completos, " INCOMPLETOS = ",incompletos)
imputados <- mice::mice(datos,m=5,meth="pmm")

datos.imputados <- mice::complete(imputados)

completos <- mice::ncc(datos.imputados)
incompletos <- mice::nic(datos.imputados)
cat("COMPLETOS = ", completos, " INCOMPLETOS = ",incompletos)

```

Con el m?todo que se ha usado, se realizan 5 imputaciones distintas, de las cuales eligiremos la que mejor se ajuste a nuestros datos. Para elegir cu?l de ellas utilizaremos, nos quedaremos con la que se distribuya de forma m?s parecida a los datos originales. En el siguiente gr?fico de densidad podemos ver para cada una de las variables imputadas la distribucion que siguen con respecto a la densidad.


Como vemos, el m?todo pmm de mice no imputa todosl os valores, aplicaremos amelia que no tiene problema para imputarlos todos.

```{r}
imputados.amelia <- Amelia::amelia(datos,m=1,parallel="multicore",noms="C")
incompletos.amelia <- mice::nic(imputados.amelia$imputations$imp1)
completos.amelia <- mice::ncc(imputados.amelia$imputations$imp1)
cat("COMPLETOS = ", completos.amelia, " INCOMPLETOS = ",incompletos.amelia)
datos <- imputados.amelia$imputations$imp1
```

#Detección de datos anómalos


```{r}
anomalos <- outliers::outlier(datos[,-ncol(datos)])
print(anomalos)
```

Al método siguiente solo se le puede pasar un argumento de menos de 10 dimensiones, por lo que si queremos ver todos los outliers que hay en todas las variables, tenemos que ponerals por separado. Además, solo considera los outliers de una dimensión, es decir, que no detecta outliers qeu estén provocados por una combiación anómala de valores de un conjhunto de variables.

```{r}
resOutliers <- mvoutlier::uni.plot(datos[1:10])
```

```{r}
print(resOutliers$outliers)
```

```{r}
datos <- datos[!resOutliers$outliers, ]
```


#Selección de caracteristicas

En primer lugar, vamos a estudiar la importancia de las variables que teemos en el problema. Para ello, en primera instancia, veremos como de correladas están entre sí. Eliminaremos aquiellas que están más correladas.


```{r}
y = cor(datos)
corrplot(y,type="upper")
```

Para ver la importancia de las variables en relación a dicha medida vamos a usar el paquete FSelector. En primer lugar calculamos los pesos de todas las variables y después me quedaré con las 20 mejores.

```{r}
pesosCorrelacion <- FSelector::linear.correlation(C~., datos)
print(pesosCorrelacion)
```

```{r}
subset.correlation <- FSelector::cutoff.k(pesosCorrelacion,20)
f <- as.simple.formula(subset.correlation,"medv")
print(f)
datos1.correlation <- datos[,subset.correlation]
datos1.correlation$C <- datos$C
test1.correlation <- test[,subset.correlation]
```


#Generación del modelo

Comprobar modelo con datos de test

```{r}
train_pred <- knn(train = datos1.correlation[,-ncol(datos)], test = datos1.correlation[,-ncol(datos)],cl = datos1.correlation$C, k=3)
accuracy <- precision(train_pred,datos$C)
accuracy
```


```{r}
test_pred <- knn(train = datos1.correlation[,-ncol(datos1.correlation)], test = test1.correlation,cl = datos1.correlation$C, k=3)
test_pred
```


```{r}
generarEnvio(y=test_pred,file="envio.csv")
```

